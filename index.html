<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="keywords" content="Jianmin Bao, 鲍建敏，中国科学技术大学"> 
<meta name="description" content="Jianmin Bao&#39;s home page">
<link rel="stylesheet" href="./Homepage_files/style/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>Jianmin Bao - Homepage</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table>
<tbody>
  <tr>
    <td width="39%" valign="top" height="193">
      <img height="225" id="photo" style="padding: 0pt 30pt 0pt 20pt; float: left; display: inline;" src="./Homepage_files/img/me.png">
    </td>
    
    <td width="60%" valign="top" height="193">
      <b><font face="Times New Roman" size="6">Jianmin Bao</font><font size="6" face="楷体_GB2312"> （鲍建敏）</font><font face="Times New Roman" size="6"></font></b>
      <br><br>    
      <p>          
          Senior Researcher
      </p>  
      <p>          
          Microsoft Research Asia
      </p> 
      <p>          
          Email: jianbao AT microsoft dot com
      </p>
      <p>[<a href="https://scholar.google.com/citations?user=hjwvkYUAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>]</p>
    </td>
  </tr>
</tbody>
</table>

<h2>Biography</h2>
<p style="text-align:justify;">
  I am currently a senior researcher in <a href="https://www.microsoft.com/en-us/research/group/visual-computing/" target="_blank">Visual Computing Group</a> at Microsoft Research Asia. Before that, I received my B.S. and Ph.D. degrees from <a href="https://www.ustc.edu.cn/" target="_blank">University of Science and Technology of China (USTC)</a> in 2014, 2019, supervised by <a href="http://www.cs.rochester.edu/u/jluo/" target="_blank">Prof. Jiebo Luo</a> and <a href="http://staff.ustc.edu.cn/~lihq/" target="_blank">Prof. Houqiang Li</a>. I collaborate closely with <a href="http://www.dongchen.pro/" target="_blank">Dong Chen</a>, Fang Wen, and <a href="https://www.ganghua.org/" target="_blank">Gang Hua</a> during my internship in MSRA.
</p>
<p> 
  My research interests focus on deep generative models (e.g., GANs, VAEs, AR, and Diffusion models), large-scale self-supervised, vision-language pretraining, and general representation learning (e.g., fundamental network structure design). I have received the best paper nominee in CVPR 2021,  I have a couple of papers(<a href="https://github.com/ZhendongWang6/Uformer" target="_blank">Uformer</a>, <a href="https://github.com/microsoft/CSWin-Transformer" target="_blank">CSWin Transformer</a>, and <a href="https://github.com/microsoft/SimMIM" target="_blank">SimMIM</a>) that are among the <a href="https://www.paperdigest.org/2023/09/most-influential-cvpr-papers-2023-09/" target="_blank">PaperDigest Most Influential Papers</a>. I serve the reviewer of many top conferences (including CVPR, ICCV, ECCV, AAAI, NeurIPs, ICML, ICLR and ACCV) and top journals (TPAMI, IJCV, TIP, TMM, TCSVT).
</p>

<tr>
    <h2>News</h2>
    <ul style="list-style-type:disc">
      <li> 4 papers are accepted by CVPR'24 with 1 paper(<a href="https://wangyanhui666.github.io/MicroCinema.github.io/" target="_blank">MicroCinema</a>) as highlight.</li>
      <li> <a href="https://github.com/ShihaoZhaoZSH/Uni-ControlNet" target="_blank">Uni-ControlNet</a> is accepted by NeurIPS 2023.</li>
      <li> 3 papers are accepted by ICCV'23.</li>
      <li> CVPR 2023 Outstanding Reviewer.</li>
      <li> <a href="https://github.com/yoctta/XPaste" target="_blank">X-Paste</a> is accepted by ICML'23.</li>
	    <li> 4 papers are accepted by CVPR'23 with 2 as highlights(2.5%).</li>
	   <li> 2 papers are accepted by ECCV'22.</li>
	    <li> 8 papers are accepted by CVPR'22.</li> 
	  <li> Code and models of CSWin Transformer are released. [<a href="https://github.com/microsoft/CSWin-Transformer" target="_blank">github</a>]</li> 
	 <li> 3 papers are accepted by ICCV'21.</li> 
	 <li> 3 papers are accepted by CVPR'21.</li> 
	
      <li> Sep. 2, 2020: Our Face X-ray is applied for fighting disinformation ahead of 2020 US election.[<a href="https://www.cnet.com/news/microsofts-new-tech-spots-deepfakes-to-fight-disinformation-ahead-2020-us-election/" target="_blank">News</a>]</li>      
    </ul>
  </tr>

<h2>Publications</h2>
     
  <table border="0" width="100%">
  <tbody> 


      <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/dire.png" alt="">
        </div>
      </td>
	 <td>
        DIRE for Diffusion-Generated Image Detection
        <br> 
		Zhendong Wang*, 
        <strong>Jianmin Bao*</strong>,  
        Wengang Zhou, Weilun Wang, Hezhen Hu, Hong Chen, and Houqiang Li.(* Equal Contribution)
        <br>
            <font size="3">International Conference on Computer Vision (<b>ICCV</b>), 2023 </font>
	</br>
        [<a href="https://arxiv.org/abs/2303.09295" target="_blank">pdf</a>]	        
	[<a href="https://github.com/ZhendongWang6/DIRE" target="_blank">code</a>]
      </td>
    </tr>



      <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/min_snr.png" alt="">
        </div>
      </td>
	 <td>
        Efficient Diffusion Training via Min-SNR Weighting Strategy
        <br> 
		Tiankai Hang, Shuyang Gu, Chen Li, <strong>Jianmin Bao </strong> , Dong Chen, Han Hu, Xin Geng, Baining Guo.
        <br>
            <font size="3">International Conference on Computer Vision (<b>ICCV</b>), 2023 </font>
	</br>
        [<a href="https://arxiv.org/pdf/2303.09556.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/TiankaiHang/Min-SNR-Diffusion-Training" target="_blank">code</a>]
      </td>
    </tr>


    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/fd_clip.png" alt="">
        </div>
      </td>
	 <td>
        Contrastive learning rivals masked image modeling in fine-tuning via feature distillation
        <br> 
        Yixuan Wei, Han Hu, Zhenda Xie, Zheng Zhang, Yue Cao, <strong>Jianmin Bao </strong> , Dong Chen, Baining Guo.
        <br>
            <font size="3">International Conference on Computer Vision (<b>ICCV</b>), 2023 </font>
	</br>
        [<a href="https://arxiv.org/pdf/2205.14141.pdf" target="_blank">pdf</a>]
      </td>
    </tr>
	
    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/x-paste.jpg" alt="">
        </div>
      </td>
	 <td>
        X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion
        <br> 
        Hanqing Zhao, Dianmo Sheng, <strong>Jianmin Bao </strong>, Dongdong Chen, Dong Chen, Fang Wen, Lu Yuan, Ce Liu, Wenbo Zhou, Qi Chu, Weiming Zhang, Nenghai Yu
        <br>
            <font size="3">International Conference on Machine Leanring (<b>ICML</b>), 2023 </font>
	</br>
        [<a href="https://arxiv.org/pdf/2205.14141.pdf" target="_blank">pdf</a>]
		[<a href="https://github.com/yoctta/XPaste" target="_blank">code</a>]
      </td>
    </tr>

    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/altfreezing.png" alt="">
        </div>
      </td>
	 <td>
    AltFreezing for More General Video Face Forgery Detection
        <br> 
		 Zhendong Wang*, 
        <strong>Jianmin Bao*</strong>,  
        Wengang Zhou, Weilun Wang, and Houqiang Li.(* Equal Contribution)
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023 (<b>Oral</b>)</font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_AltFreezing_for_More_General_Video_Face_Forgery_Detection_CVPR_2023_paper.pdf" target="_blank">pdf</a>]	        
      </td>
    </tr>

  
    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/maskclip.png" alt="">
        </div>
      </td>
	 <td>
    MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining
        <br> 
		 Xiaoyi Dong*, 
        <strong>Jianmin Bao*</strong>,  
        Yinglin Zheng, Ting Zhang, Dongdong Chen,
, Hao Yang,Ming Zeng, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu.(* Equal Contribution)
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_MaskCLIP_Masked_Self-Distillation_Advances_Contrastive_Language-Image_Pretraining_CVPR_2023_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/LightDXY/MaskCLIP/" target="_blank">code</a>]
      </td>
    </tr>


    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/rodin.png" alt="">
        </div>
      </td>
	 <td>
    RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion
        <br> 
		 Tengfei Wang, Bo Zhang, Ting Zhang, Shuyang Gu, 
        <strong>Jianmin Bao</strong>, 
        Tadas Baltrusaitis,
        Jingjing Shen, Dong Chen, Fang Wen, Qifeng Chen, and Baining Guo.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023 (<b>Oral</b>)</font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_RODIN_A_Generative_Model_for_Sculpting_3D_Digital_Avatars_Using_CVPR_2023_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://3d-avatar-diffusion.microsoft.com/" target="_blank">project</a>]
      </td>
    </tr>

	  <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/cico.png" alt="">
        </div>
      </td>
	 <td>
    CiCo: Domain-Aware Sign Language Retrieval via Cross-Lingual Contrastive Learning
        <br> 
		Yiting Cheng, Fangyun Wei		
        <strong>Jianmin Bao</strong>, 
         Dong Chen, Wenqiang Zhang.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_CiCo_Domain-Aware_Sign_Language_Retrieval_via_Cross-Lingual_Contrastive_Learning_CVPR_2023_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/FangyunWei/SLRT" target="_blank">code</a>]
      </td>
    </tr>


      <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/bootmae.PNG" alt="">
        </div>
      </td>
	 <td>
        Bootstrapped Masked Autoencoders for Vision BERT Pretraining
        <br> 
		Xiaoyi Dong,
        <strong>Jianmin Bao</strong>, 		
        Ting Zhang, Dongdong Chen, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu.       
        <br>
		 <font size="3">European Conference on Computer Vision(<b>ECCV</b>), 2022</font>
	</br>
        [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136900246.pdf" target="_blank">pdf</a>]
	[<a href="https://github.com/LightDXY/BootMAE" target="_blank">code</a>]
      </td>
    </tr> 
	
    
          <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/trace-t2i.PNG" alt="">
        </div>
      </td>
	 <td>
        Trace Controlled Text to Image Generation
        <br> 
		Kun Yan, Lei Ji, Chenfei Wu,
        <strong>Jianmin Bao</strong>, 		
        Ming Zhou, Nan Duan, Shuai Ma.    
        <br>
		 <font size="3">European Conference on Computer Vision(<b>ECCV</b>), 2022</font>
	</br>
        [<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136960058.pdf" target="_blank">pdf</a>]
      </td>
    </tr> 
	


	  <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/uformer.png" alt="">
        </div>
      </td>
	 <td>
        Uformer: A General U-Shaped Transformer for Image Restoration
        <br> 
		Zhendong wang, Xiaodong Cun,		
        <strong>Jianmin Bao</strong>, 
		Wengang Zhou, Jianzhuang Liu, Houqiang Li
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/ZhendongWang6/Uformer" target="_blank">code</a>]
	  <a href="https://www.paperdigest.org/2023/01/most-influential-cvpr-papers-2023-01/" target="_blank"><strong>PaperDigest Most Influential Papers</strong></a>
      </td>
    </tr>
	
	  <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/cswin.png" alt="">
        </div>
      </td>
	 <td>
    CSWin Transformer: A General Vision Transformer Backbone With Cross-Shaped Windows
        <br> 
		Xiaoyi Dong,		
        <strong>Jianmin Bao</strong>, 
        Dongdong Chen, Weiming Zhang, Nenghai Yu, Lu Yuan, Dong Chen, Baining Guo.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/microsoft/CSWin-Transformer" target="_blank">code</a>]
	  <a href="https://www.paperdigest.org/2023/01/most-influential-cvpr-papers-2023-01/" target="_blank"><strong>PaperDigest Most Influential Papers</strong></a>
      </td>
    </tr>

    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/simmim.png" alt="">
        </div>
      </td>
	 <td>
    SimMIM: A Simple Framework for Masked Image Modeling
        <br> 
        Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin,		
        <strong>Jianmin Bao</strong>, 
        Zhuliang Yao, Qi Dai, Han Hu.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/microsoft/SimMIM" target="_blank">code</a>]
	  <a href="https://www.paperdigest.org/2023/01/most-influential-cvpr-papers-2023-01/" target="_blank"><strong>PaperDigest Most Influential Papers</strong></a>
      </td>
    </tr>
  
    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/styleswin.png" alt="">
        </div>
      </td>
	 <td>
    StyleSwin: Transformer-Based GAN for High-Resolution Image Generation
        <br> 
        Bowen Zhang, Shuyang Gu, Bo Zhang,		
        <strong>Jianmin Bao</strong>, 
        Dong Chen, Fang Wen, Yong Wang, Baining Guo.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/microsoft/StyleSwin" target="_blank">code</a>]
      </td>
    </tr>

    <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/pnl.png" alt="">
        </div>
      </td>
	 <td>
    Large-Scale Pre-Training for Person Re-Identification With Noisy Labels
        <br> 
        Dengpan Fu, Dongdong Chen, Hao Yang,		
        <strong>Jianmin Bao</strong>, 
        Lu Yuan, Lei Zhang, Houqiang Li, Fang Wen, Dong Chen.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Large-Scale_Pre-Training_for_Person_Re-Identification_With_Noisy_Labels_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	        
      </td>
    </tr>
    
        <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/farl.PNG" alt="">
        </div>
      </td>
	 <td>
    General Facial Representation Learning in a Visual-Linguistic Manner
        <br> 
        Yinglin Zheng, Hao Yang, Ting Zhang,		
        <strong>Jianmin Bao</strong>, 
        Dongdong Chen, Yangyu Huang, Lu Yuan, Dong Chen, Ming Zeng, Fang Wen.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 (<b>Oral</b>) </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	        
      </td>
    </tr>

        <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/vq-diffusion.PNG" alt="">
        </div>
      </td>
	 <td>
    Vector Quantized Diffusion Model for Text-to-Image Synthesis
        <br> 
        Shuyang Gu, Dong Chen,		
        <strong>Jianmin Bao</strong>, 
        Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, Baining Guo.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 (<b>Oral</b>) </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	
 [<a href="https://github.com/cientgu/VQ-Diffusion" target="_blank">code</a>]        
      </td>
    </tr>

        <tr>
      <td>
        <div align="center">
          <img width="240" src="./paper_imgs/ict.PNG" alt="">
        </div>
      </td>
	 <td>
    Protecting Celebrities From DeepFake With Identity Consistency Transformer
        <br> 
        Xiaoyi Dong,,		
        <strong>Jianmin Bao</strong>, 
        Dongdong Chen, Ting Zhang, Weiming Zhang, Nenghai Yu, Dong Chen, Fang Wen, Baining Guo.
        <br>
            <font size="3">IEEE/CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022 </font>
	</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Protecting_Celebrities_From_DeepFake_With_Identity_Consistency_Transformer_CVPR_2022_paper.pdf" target="_blank">pdf</a>]	
 [<a href="https://github.com/LightDXY/ICT_DeepFake" target="_blank">code</a>]        
      </td>
    </tr>


        <tr>
      <td>
        <div align="center">
          <img width="240" src="./FTCN/main.png" alt="">
        </div>
      </td>
	 <td>
        Exploring Temporal Coherence for More General Video Face Forgery Detection
        <br> 
		Yinglin Zheng,		
        <strong>Jianmin Bao</strong>, 
		<a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, Ming Zeng, and Fang Wen.
        <br>
            <font size="3">International Conference on Computer Vision (<b>ICCV</b>), 2021 </font>
	</br>
        [<a href="https://arxiv.org/abs/2108.06693" target="_blank">pdf</a>]	        
	[<a href="https://github.com/yinglinzheng/FTCN" target="_blank">code</a>]
      </td>
    </tr>
	
	      <tr>
      <td>
        <div align="center">
          <img width="240" src="./NEGCUT/main.png" alt="">
        </div>
      </td>
	 <td>
        Instance-wise Hard Negative Example Generation for Contrastive Learning in Unpaired Image-to-Image Translation
        <br> 
		Weilun Wang,
		Wengang Zhou,
        <strong>Jianmin Bao</strong>, 
		<a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, and Houqiang Li.         
        <br>
            <font size="3">International Conference on Computer Vision (<b>ICCV</b>), 2021 </font>
	</br>
        [<a href="https://arxiv.org/pdf/2108.04547.pdf" target="_blank">pdf</a>]	        
	[<a href="https://github.com/Cyclocosmia-ricketti/NEGCUT" target="_blank">code</a>]
      </td>
    </tr>
	
	      <tr>
      <td>
        <div align="center">
          <img width="240" src="./DPL/main.png" alt="">
        </div>
      </td>
	 <td>
        Dual Path Learning for Domain Adaptation of Semantic Segmentation
        <br> 
		Yiting Cheng, Fangyun Wei,		
        <strong>Jianmin Bao</strong>, 
		 <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, Fang Wen, and Wenqiang Zhang.         
        <br>
            <font size="3">International Conference on Computer Vision (<b>ICCV</b>), 2021 </font>
	</br>
        [<a href="https://arxiv.org/abs/2108.06337" target="_blank">pdf</a>]	        
	  [<a href="https://github.com/royee182/DPL" target="_blank">code</a>]
      </td>
    </tr>
  
      <tr>
      <td>
        <div align="center">
          <img width="240" src="./LUPerson/main.png" alt="">
        </div>
      </td>
	 <td>
        Unsupervised Pre-training for Person Re-identification
        <br> 
		Dengpan Fu,
		<a href="http://www.dongdongchen.bid/" target="_blank" onclick="stc(this, 44)">Dongdong Chen</a>,
        <strong>Jianmin Bao</strong>, 
		<a href="https://www.microsoft.com/en-us/research/people/haya/" target="_blank" onclick="stc(this, 44)">Hao Yang</a>, 
        Lu Yuan, Lei Zhang, <a href="http://staff.ustc.edu.cn/~lihq/" target="_blank" onclick="stc(this, 44)">Houqiang Li</a>, and <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>.         
        <br>
            <font size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021 </font>
	</br>
        [<a href="https://arxiv.org/pdf/2012.03753v2.pdf" target="_blank">pdf</a>]	
        [<a href="./LUPerson/bibtex.txt" target="_blank">bibtex</a>]
	[<a href="https://github.com/DengpanFu/LUPerson" target="_blank">code</a>]
      </td>
    </tr>
  
      <tr>
      <td>
        <div align="center">
          <img width="240" src="./HifaFace/main.png" alt="">
        </div>
      </td>
	 <td>
        High-Fidelity and Arbitrary Face Editing
        <br> 
		Yue Gao, Fangyun Wei,
        <strong>Jianmin Bao</strong>, 
		<a href="https://www.microsoft.com/en-us/research/people/haya/" target="_blank" onclick="stc(this, 44)">Hao Yang</a>, 
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 		
        Fang Wen,
		and Zhouhui Lian.
        <br>
            <font size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021 </font>
	</br>
        [<a href="https://arxiv.org/abs/2103.15814" target="_blank">pdf</a>]	
        [<a href="./HifaFace/bibtex.txt" target="_blank">bibtex</a>]
      </td>
    </tr>
  
      <tr>
      <td>
        <div align="center">
          <img width="240" src="./Full_resolution_correspondence/main.png" alt="">
        </div>
      </td>
	 <td>
        CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation
        <br> 
		Xingran Zhou, Bo Zhang, Ting Zhang, Pan Zhang,
        <strong>Jianmin Bao</strong>, 
		<a href="https://www.microsoft.com/en-us/research/people/haya/" target="_blank" onclick="stc(this, 44)">Hao Yang</a>, 
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, Zhongfei Zhang,
		and
        Fang Wen.        
        <br>
            <font size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021 (<b>Oral</b>)</font>
	</br>
        [<a href="https://arxiv.org/pdf/2012.02047.pdf" target="_blank">pdf</a>]	
        [<a href="./Full_resolution_correspondence/bibtex.txt" target="_blank">bibtex</a>]
      </td>
    </tr>
  
  
        <tr>
      <td>
        <div align="center">
          <img width="240" src="./GreedyFool/main.jpg" alt="">
        </div>
      </td>
	 <td>
        GreedyFool: Distortion-Aware Sparse Adversarial Attack
        <br> 
		Xiaoyi Dong, 		
		<a href="http://www.dongdongchen.bid/" target="_blank" onclick="stc(this, 44)">Dongdong Chen</a>, 
        <strong>Jianmin Bao</strong>, 		
        Chuan Qin,
		Lu Yuan,
		Weiming Zhang,
		Nenghai Yu,
		and
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>
        <br>
		 <font size="3">Neural Information Processing Systems (<b>NeurIPS</b> 2020)</font>
	    </br>
    [<a href="https://arxiv.org/pdf/2009.10066.pdf" target="_blank">pdf</a>]	
	[<a href="https://github.com/LightDXY/GreedyFool" target="_blank">code</a>]  
      </td>
    </tr> 


      <tr>
      <td>
        <div align="center">
          <img width="240" src="./IIA/main.jpg" alt="">
        </div>
      </td>
	 <td>
        Improving Person Re-identification with Iterative Impression Aggregation
        <br> 
		Dengpan Fu, 
		<a href="https://sites.google.com/site/jimxinbo/" target="_blank" onclick="stc(this, 44)">Bo Xin</a>, 
		<a href="https://jingdongwang2017.github.io/" target="_blank" onclick="stc(this, 44)">Jingdong Wang</a>, 
		<a href="http://www.dongdongchen.bid/" target="_blank" onclick="stc(this, 44)">Dongdong Chen</a>, 
        <strong>Jianmin Bao</strong>, 		
        <a href="https://www.ganghua.org/" target="_blank" onclick="stc(this, 44)">Gang Hua</a>
		and
        <a href="http://staff.ustc.edu.cn/~lihq/" target="_blank" onclick="stc(this, 44)">Houqiang Li</a>,  
        <br>
		 <font size="3">IEEE Transactions on Image Processing(<b>TIP</b>)</font>
	    </br>
    [<a href="https://arxiv.org/pdf/2009.10066.pdf" target="_blank">pdf</a>]	
	[<a href="./IIA/bibtex.txt" target="_blank">bibtex</a>]  
      </td>
    </tr> 
	
      <tr>
      <td>
        <div align="center">
          <img width="240" src="./GIQA/main.jpg" alt="">
        </div>
      </td>
	 <td>
        GIQA: Generated Image Quality Assessment
        <br> 
		Shuyang Gu,
        <strong>Jianmin Bao</strong>, 		
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 
		and
        Fang Wen.        
        <br>
		 <font size="3">European Conference on Computer Vision(<b>ECCV</b>), 2020</font>
	</br>
        [<a href="https://arxiv.org/abs/2003.08932" target="_blank">pdf</a>]
	[<a href="https://github.com/cientgu/GIQA" target="_blank">code</a>]
	[<a href="./GIQA/bibtex.txt" target="_blank">bibtex</a>]  
      </td>
    </tr> 
	
    <tr>
      <td>
        <div align="center">
          <img width="240" src="./FaceShifter/main.jpg" alt="">
        </div>
      </td>
	 <td>
        FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping
        <br> 
		Lingzhi Li,
        <strong>Jianmin Bao</strong>, 
		<a href="https://www.microsoft.com/en-us/research/people/haya/" target="_blank" onclick="stc(this, 44)">Hao Yang</a>, 
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 
		and
        Fang Wen.        
        <br>
            <font size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020 (<b>Oral</b>)</font>
	</br>
        [<a href="https://arxiv.org/abs/1912.13457" target="_blank">pdf</a>]
	[<a href="https://lingzhili.com/FaceShifterPage/" target="_blank">project</a>]
        [<a href="./FaceShifter/bibtex.txt" target="_blank">bibtex</a>]
      </td>
    </tr> 


    <tr>
      <td>
        <div align="center">
          <img width="240" src="./Face-X-Ray/main.jpg" alt="">
        </div>
      </td>
	 <td>
        Face X-ray for More General Face Forgery Detection
        <br> 
		Lingzhi Li*,
        <strong>Jianmin Bao*</strong>, 
		<a href="https://www.microsoft.com/en-us/research/people/tinzhan/" target="_blank" onclick="stc(this, 44)">Ting Zhang</a>, 
		<a href="https://www.microsoft.com/en-us/research/people/haya/" target="_blank" onclick="stc(this, 44)">Hao Yang</a>, 
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 
        Fang Wen, 
		and 
        <a href="https://www.microsoft.com/en-us/research/people/bainguo/" target="_blank" onclick="stc(this, 44)">Baining Guo</a>
        <br>
            <font size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020 (<b>Oral</b>)</font>
	</br>
        [<a href="./Face-X-Ray/main.pdf" target="_blank">pdf</a>]
        [<a href="./Face-X-Ray/bibtex.txt" target="_blank">bibtex</a>]   
        [<a href="https://github.com/AlgoHunt/Face-Xray" target="_blank">code</a>]
        <br>
        (*: Equal contributions)
      </td>
    </tr> 	

    <tr>
      <td>
        <div align="center">
          <img width="240" src="./Mask-guied-portrait-editing/editing.jpg" alt="">
        </div>
      </td>
	 <td>
        Mask-Guided Portrait Editing With Conditional GANs
        <br> 
		Shuyang Gu,
        <strong>Jianmin Bao</strong>, 
		Hao Yang,
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 
        Fang Wen, 
		and 
        <a href="https://www.microsoft.com/en-us/research/people/luyuan/" target="_blank" onclick="stc(this, 44)">Lu Yuan</a>
        <br>
            <font  size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019 </font>
	</br>
        [<a href="./Mask-guied-portrait-editing/main.pdf" target="_blank">pdf</a>]        
	[<a href="https://github.com/cientgu/Mask_Guided_Portrait_Editing" target="_blank">code</a>]
        [<a href="./Mask-guied-portrait-editing/bibtex.txt" target="_blank">bibtex</a>]
      </td>
    </tr> 

    <tr>
      <td>
        <div align="center">
          <img width="240" src="./IP-GAN/IP-GAN.jpg" alt="">
        </div>
      </td>	  
      <td>
        Towards Open-Set Identity Preserving Face Synthesis
        <br> 
        <strong>Jianmin Bao</strong>, 
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 
        Fang Wen, 
		<a href="http://staff.ustc.edu.cn/~lihq/" target="_blank" onclick="stc(this, 44)">Houqiang Li</a>, 
		and 
        <a href="https://www.ganghua.org/" target="_blank" onclick="stc(this, 44)">Gang Hua</a>
       <br>
            <font  size="3">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018 </font>
	</br>
        [<a href="./IP-GAN/IP-GAN.pdf" target="_blank">pdf</a>]
        [<a href="./IP-GAN/IP-GAN_video.mp4" target="_blank">video</a>] 
        [<a href="./IP-GAN/IP-GAN_supp.pdf" target="_blank">supplementary</a>] 
        [<a href="./IP-GAN/bibtex.txt" target="_blank">bibtex</a>]         
      </td>
    </tr>  	
	
	    <tr>
      <td>
        <div align="center">
          <img width="240" src="./CVAE-GAN/CVAE-GAN.jpg" alt="">
        </div>
      </td>
      <td>
        CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training
        <br> 
        <strong>Jianmin Bao</strong>, 
        <a href="http://www.dongchen.pro/" target="_blank" onclick="stc(this, 44)">Dong Chen</a>, 
        Fang Wen, 
		<a href="http://staff.ustc.edu.cn/~lihq/" target="_blank" onclick="stc(this, 44)">Houqiang Li</a>, 
		and 
        <a href="https://www.ganghua.org/" target="_blank" onclick="stc(this, 44)">Gang Hua</a>
       <br>
            <font  size="3">International Conference on Computer Vision(<b>ICCV</b>), 2017 </font>
	</br>
        [<a href="./CVAE-GAN/CVAE-GAN.pdf" target="_blank">pdf</a>]
        [<a href="./CVAE-GAN/CVAE-GAN_video.mp4" target="_blank">video</a>] 
	[<a href="./CVAE-GAN/CVAE-GAN_supp.pdf" target="_blank">supplementary</a>] 
        [<a href="./CVAE-GAN/bibtex.txt" target="_blank">bibtex</a>]         
      </td>
    </tr> 
    
     <tr>
      <td>
        <div align="center">
          <img width="240" src="./thesis/main.png" alt="">
        </div>
      </td>
      <td>
        基于生成对抗网络的图像合成
        <br> 
        <strong>Jianmin Bao</strong>
        <br>
	     <font  size="3">博士毕业论文, 2019 </font>
	</br>
        [<a href="./thesis/main.pdf" target="_blank">pdf</a>]        
      </td>
    </tr>    
    
  </tbody>
  </table>
 
<h2>Academic Services</h2>
<table id="tbExperiences" border="0" width="100%">
  <tbody>	
     <tr>
      <td> Reviewer: CVPR 2019, CVPR 2020, NeurIPS 2020</td>
    </tr>
     <tr>
      <td> Program Committee member: AAAI 2019, AAAI 2020</td>
    </tr>
    <tr>
      <td> Reviewer: ICCV 2019, ECCV 2020</td>
    </tr>
     <tr>
      <td> Reviewer: Neurocomputing</td>
    </tr>	
	 <tr>
      <td> Reviewer: Transactions on Multimedia, International Journal of Computer Vision</td>
    </tr>
  </tbody>
</table> 
 
<h2>Experiences</h2>
<table id="tbExperiences" border="0" width="100%">
  <tbody>
     <tr>
      <td> Jun.2019 - Present &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Senior Researcher, Visual Computing Group, Microsoft Research Asia</td>
    </tr>
    <tr>
      <td> Apr. 2016 - Jun.2019 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research Intern, Visual Computing Group, Microsoft Research Asia</td>
    </tr>
    <tr>
      <td> Jul. 2013 - Jun. 2014 &nbsp;&nbsp; Research Intern, Wireless and Network Group, Microsoft Research Asia</td>
    </tr>
  </tbody>
</table> 



<h2>Awards and Honors</h2>
<table id="tbExperiences" border="0" width="100%">
  <tbody>
    <tr>
      <td><strong>Rank 3/2950 teams</strong>, Fahsion AI Global Challenge - Attributes Recognition of Apparel, Alibaba, Jul. 2018</td>
    </tr>
	<tr>
      <td><strong>Rank 7/2322 teams</strong>, Fahsion AI Global Challenge - Key Points Detection of Apparel, Alibaba, Jul. 2018</td>
    </tr>
    <tr>
      <td><strong>Rank 1/1386 teams</strong>, Pig Face Recognition Challenge, JingDong, Nov. 2017</td>
    </tr>
  </tbody>
</table> 

<!-- Default Statcounter code for JianminBao's Homepage
https://jianminbao.github.io/ -->
<h2></h2>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=uZ8BI7fPH9kpWPUfOgpU4pVBHOLczY98e-Pp1DC8JBE'></script>
</div>
</body>
</html>
